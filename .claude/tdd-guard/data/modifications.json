{
  "session_id": "096b9c55-d8c1-48d6-8b36-f3623cc4de98",
  "transcript_path": "/Users/hue/.claude/projects/-Users-hue-code-Dopemux-ChatRipperXXX/096b9c55-d8c1-48d6-8b36-f3623cc4de98.jsonl",
  "hook_event_name": "PreToolUse",
  "tool_name": "Write",
  "tool_input": {
    "file_path": "src/chatx/enrichment/image_enricher.py",
    "content": "\"\"\"Image enrichment pipeline for detecting objects, OCR, and psychological analysis.\"\"\"\n\nimport asyncio\nimport hashlib\nimport json\nimport logging\nimport uuid\nfrom pathlib import Path\nfrom typing import Any, Dict, List, Optional, Tuple\nfrom datetime import datetime\n\nimport PIL.Image\nfrom chatx.schemas.validator import validate_data\n\nlogger = logging.getLogger(__name__)\n\n\nclass ImageEnrichmentRequest:\n    \"\"\"Request for image enrichment processing.\"\"\"\n\n    def __init__(\n        self,\n        msg_id: str,\n        attachment_index: int,\n        image_path: Optional[Path] = None,\n        image_data: Optional[bytes] = None,\n        provenance: Optional[Dict[str, Any]] = None,\n        context_hints: Optional[Dict[str, Any]] = None,\n    ):\n        \"\"\"Initialize image enrichment request.\n\n        Args:\n            msg_id: Message ID containing the image\n            attachment_index: Index of attachment in message\n            image_path: Path to image file (alternative to image_data)\n            image_data: Raw image bytes (alternative to image_path)\n            provenance: Processing metadata\n            context_hints: Additional context from message\n        \"\"\"\n        self.msg_id = msg_id\n        self.attachment_index = attachment_index\n        self.image_path = image_path\n        self.image_data = image_data\n        self.provenance = provenance or {}\n        self.context_hints = context_hints or {}\n\n    @property\n    def hash_sha256(self) -> str:\n        \"\"\"Compute SHA256 hash of image data.\"\"\"\n        if self.image_data:\n            return hashlib.sha256(self.image_data).hexdigest()\n        elif self.image_path and self.image_path.exists():\n            with open(self.image_path, 'rb') as f:\n                return hashlib.sha256(f.read()).hexdigest()\n        return \"\"\n\n\nclass ImageEnrichment:\n    \"\"\"Complete image enrichment result.\"\"\"\n\n    def __init__(\n        self,\n        msg_id: str,\n        attachment_index: int,\n        hash_sha256: str,\n        provenance: Dict[str, Any],\n        ocr_text: Optional[str] = None,\n        objects: Optional[List[Dict[str, Any]]] = None,\n        category: Optional[str] = None,\n        caption: Optional[Dict[str, Any]] = None,\n        tags: Optional[List[str]] = None,\n        faces: Optional[Dict[str, Any]] = None,\n        similarity: Optional[Dict[str, Any]] = None,\n        nsfw_risk: Optional[float] = None,\n        psych: Optional[Dict[str, Any]] = None,\n    ):\n        \"\"\"Initialize image enrichment result.\n\n        Args:\n            msg_id: Message ID\n            attachment_index: Attachment index\n            hash_sha256: Image hash\n            provenance: Processing metadata\n            ocr_text: Extracted text content\n            objects: Detected objects with bounding boxes\n            category: Image category classification\n            caption: Generated captions\n            tags: Content tags\n            faces: Face detection results (count only, privacy-focused)\n            similarity: Similarity analysis\n            nsfw_risk: NSFW content risk score\n            psych: Psychological analysis results\n        \"\"\"\n        self.msg_id = msg_id\n        self.attachment_index = attachment_index\n        self.hash_sha256 = hash_sha256\n        self.provenance = provenance\n        self.ocr_text = ocr_text\n        self.objects = objects or []\n        self.category = category\n        self.caption = caption\n        self.tags = tags or []\n        self.faces = faces\n        self.similarity = similarity\n        self.nsfw_risk = nsfw_risk\n        self.psych = psych\n\n    def dict(self) -> Dict[str, Any]:\n        \"\"\"Convert to dictionary for JSON serialization.\"\"\"\n        result = {\n            \"msg_id\": self.msg_id,\n            \"attachment_index\": self.attachment_index,\n            \"hash_sha256\": self.hash_sha256,\n            \"provenance\": self.provenance,\n        }\n\n        # Add optional fields only if they exist\n        if self.ocr_text is not None:\n            result[\"ocr\"] = {\"text\": self.ocr_text}\n        if self.objects:\n            result[\"objects\"] = self.objects\n        if self.category:\n            result[\"category\"] = self.category\n        if self.caption:\n            result[\"caption\"] = self.caption\n        if self.tags:\n            result[\"tags\"] = self.tags\n        if self.faces:\n            result[\"faces\"] = self.faces\n        if self.similarity:\n            result[\"similarity\"] = self.similarity\n        if self.nsfw_risk is not None:\n            result[\"nsfw_risk\"] = self.nsfw_risk\n        if self.psych:\n            result[\"psych\"] = self.psych\n\n        return result\n\n\nclass ImageEnricher:\n    \"\"\"Privacy-focused image enrichment pipeline.\"\"\"\n\n    def __init__(\n        self,\n        ocr_enabled: bool = True,\n        object_detection_enabled: bool = True,\n        vlm_enabled: bool = True,\n        validate_schemas: bool = True,\n    ):\n        \"\"\"Initialize image enricher.\n\n        Args:\n            ocr_enabled: Enable OCR processing\n            object_detection_enabled: Enable object detection\n            vlm_enabled: Enable VLM psychological analysis\n            validate_schemas: Validate results against schemas\n        \"\"\"\n        self.ocr_enabled = ocr_enabled\n        self.object_detection_enabled = object_detection_enabled\n        self.vlm_enabled = vlm_enabled\n        self.validate_schemas = validate_schemas\n\n        self.run_id = str(uuid.uuid4())\n        logger.info(f\"Initialized ImageEnricher with run_id: {self.run_id}\")\n\n    async def __aenter__(self):\n        \"\"\"Async context manager entry.\"\"\"\n        # Initialize VLM client if needed\n        return self\n\n    async def __aexit__(self, exc_type, exc_val, exc_tb):\n        \"\"\"Async context manager exit.\"\"\"\n        pass\n\n    async def enrich_image(\n        self,\n        request: ImageEnrichmentRequest\n    ) -> Tuple[Optional[ImageEnrichment], Dict[str, Any]]:\n        \"\"\"Enrich a single image.\n\n        Args:\n            request: Image enrichment request\n\n        Returns:\n            Tuple of (enrichment_result, processing_metadata)\n        \"\"\"\n        try:\n            start_time = datetime.now()\n\n            # Load image\n            if request.image_path:\n                image = PIL.Image.open(request.image_path)\n            elif request.image_data:\n                image = PIL.Image.open(io.BytesIO(request.image_data))\n            else:\n                return None, {\"error\": \"no_image_data\"}\n\n            # OCR processing\n            ocr_result = None\n            if self.ocr_enabled:\n                ocr_result = await self._extract_ocr(image, request)\n\n            # Object detection\n            objects_result = None\n            if self.object_detection_enabled:\n                objects_result = await self._detect_objects(image, request)\n\n            # Category classification (placeholder)\n            category_result = await self._classify_category(image, request)\n\n            # Caption generation (placeholder)\n            caption_result = await self._generate_caption(image, request)\n\n            # Tag extraction (placeholder)\n            tags_result = await self._extract_tags(image, request)\n\n            # Face detection (privacy-focused - count only)\n            faces_result = await self._detect_faces(image, request)\n\n            # NSFW risk assessment (placeholder)\n            nsfw_result = await self._assess_nsfw_risk(image, request)\n\n            # Psychological analysis (VLM-based)\n            psych_result = None\n            if self.vlm_enabled:\n                psych_result = await self._analyze_psychology(image, request)\n\n            # Create enrichment result\n            enrichment = ImageEnrichment(\n                msg_id=request.msg_id,\n                attachment_index=request.attachment_index,\n                hash_sha256=request.hash_sha256,\n                provenance=request.provenance,\n                ocr_text=ocr_result,\n                objects=objects_result,\n                category=category_result,\n                caption=caption_result,\n                tags=tags_result,\n                faces=faces_result,\n                nsfw_risk=nsfw_result,\n                psych=psych_result,\n            )\n\n            # Validate against schema\n            if self.validate_schemas:\n                is_valid, errors = validate_data(enrichment.dict(), \"image_enrichment\", strict=False)\n                if not is_valid:\n                    logger.warning(f\"Schema validation failed for image {request.msg_id}: {errors}\")\n                    return None, {\"validation_errors\": errors, \"partial_result\": enrichment.dict()}\n\n            processing_time = (datetime.now() - start_time).total_seconds() * 1000\n            metadata = {\n                \"processing_time_ms\": processing_time,\n                \"run_id\": self.run_id,\n                \"features_processed\": {\n                    \"ocr\": ocr_result is not None,\n                    \"objects\": objects_result is not None,\n                    \"category\": category_result is not None,\n                    \"caption\": caption_result is not None,\n                    \"tags\": tags_result is not None,\n                    \"faces\": faces_result is not None,\n                    \"nsfw\": nsfw_result is not None,\n                    \"psych\": psych_result is not None,\n                }\n            }\n\n            return enrichment, metadata\n\n        except Exception as e:\n            logger.error(f\"Error enriching image {request.msg_id}: {e}\")\n            return None, {\"error\": str(e)}\n\n    async def _extract_ocr(\n        self,\n        image: PIL.Image.Image,\n        request: ImageEnrichmentRequest\n    ) -> Optional[str]:\n        \"\"\"Extract text from image using OCR.\n\n        Args:\n            image: PIL Image object\n            request: Enrichment request\n\n        Returns:\n            Extracted text or None if failed\n        \"\"\"\n        # Placeholder for OCR implementation\n        # In a full implementation, this would use Tesseract or similar\n        logger.debug(f\"OCR processing for {request.msg_id} (placeholder)\")\n        return None\n\n    async def _detect_objects(\n        self,\n        image: PIL.Image.Image,\n        request: ImageEnrichmentRequest\n    ) -> Optional[List[Dict[str, Any]]]:\n        \"\"\"Detect objects in image.\n\n        Args:\n            image: PIL Image object\n            request: Enrichment request\n\n        Returns:\n            List of detected objects with bounding boxes or None if failed\n        \"\"\"\n        # Placeholder for object detection implementation\n        # In a full implementation, this would use YOLOv8 or similar\n        logger.debug(f\"Object detection for {request.msg_id} (placeholder)\")\n\n        # Return placeholder result for testing\n        return [\n            {\n                \"label\": \"person\",\n                \"conf\": 0.85,\n                \"box\": [0.1, 0.2, 0.3, 0.4]\n            }\n        ]\n\n    async def _classify_category(\n        self,\n        image: PIL.Image.Image,\n        request: ImageEnrichmentRequest\n    ) -> Optional[str]:\n        \"\"\"Classify image category.\n\n        Args:\n            image: PIL Image object\n            request: Enrichment request\n\n        Returns:\n            Image category or None if failed\n        \"\"\"\n        # Placeholder for category classification\n        logger.debug(f\"Category classification for {request.msg_id} (placeholder)\")\n        return \"photo\"\n\n    async def _generate_caption(\n        self,\n        image: PIL.Image.Image,\n        request: ImageEnrichmentRequest\n    ) -> Optional[Dict[str, Any]]:\n        \"\"\"Generate image caption.\n\n        Args:\n            image: PIL Image object\n            request: Enrichment request\n\n        Returns:\n            Caption dictionary or None if failed\n        \"\"\"\n        # Placeholder for caption generation\n        logger.debug(f\"Caption generation for {request.msg_id} (placeholder)\")\n        return {\"short\": \"A placeholder caption\"}\n\n    async def _extract_tags(\n        self,\n        image: PIL.Image.Image,\n        request: ImageEnrichmentRequest\n    ) -> Optional[List[str]]:\n        \"\"\"Extract content tags.\n\n        Args:\n            image: PIL Image object\n            request: Enrichment request\n\n        Returns:\n            List of tags or None if failed\n        \"\"\"\n        # Placeholder for tag extraction\n        logger.debug(f\"Tag extraction for {request.msg_id} (placeholder)\")\n        return [\"placeholder\", \"tag\"]\n\n    async def _detect_faces(\n        self,\n        image: PIL.Image.Image,\n        request: ImageEnrichmentRequest\n    ) -> Optional[Dict[str, Any]]:\n        \"\"\"Detect faces (privacy-focused - count only).\n\n        Args:\n            image: PIL Image object\n            request: Enrichment request\n\n        Returns:\n            Face detection results (count only) or None if failed\n        \"\"\"\n        # Placeholder for face detection (privacy-focused)\n        logger.debug(f\"Face detection for {request.msg_id} (placeholder - privacy focused)\")\n        return {\"count\": 1, \"blurred\": False}\n\n    async def _assess_nsfw_risk(\n        self,\n        image: PIL.Image.Image,\n        request: ImageEnrichmentRequest\n    ) -> Optional[float]:\n        \"\"\"Assess NSFW content risk.\n\n        Args:\n            image: PIL Image object\n            request: Enrichment request\n\n        Returns:\n            NSFW risk score (0.0-1.0) or None if failed\n        \"\"\"\n        # Placeholder for NSFW assessment\n        logger.debug(f\"NSFW assessment for {request.msg_id} (placeholder)\")\n        return 0.1\n\n    async def _analyze_psychology(\n        self,\n        image: PIL.Image.Image,\n        request: ImageEnrichmentRequest\n    ) -> Optional[Dict[str, Any]]:\n        \"\"\"Analyze psychological signals in image.\n\n        Args:\n            image: PIL Image object\n            request: Enrichment request\n\n        Returns:\n            Psychological analysis results or None if failed\n        \"\"\"\n        # Placeholder for VLM psychological analysis\n        logger.debug(f\"Psychological analysis for {request.msg_id} (placeholder)\")\n\n        # Return placeholder psych analysis structure\n        return {\n            \"coarse_labels\": [\"communication\"],\n            \"fine_labels_local\": [\"casual_interaction\"],\n            \"emotion_hint\": \"neutral\",\n            \"interaction_type\": \"other\",\n            \"power_balance\": 0.0,\n            \"boundary_health\": \"none\",\n            \"confidence\": 0.8,\n            \"provenance\": {\n                \"schema_v\": \"1\",\n                \"run_id\": self.run_id,\n                \"model_id\": \"placeholder-vlm\",\n                \"prompt_hash\": \"placeholder_hash\",\n                \"source\": \"local\",\n            }\n        }\n\n\nclass ImageEnrichmentMetrics:\n    \"\"\"Metrics tracking for image enrichment pipeline.\"\"\"\n\n    def __init__(self):\n        self.images_processed = 0\n        self.enrichments_generated = 0\n        self.processing_errors = 0\n        self.validation_errors = 0\n        self.total_processing_time_ms = 0.0\n\n    def record_enrichment(self, success: bool, processing_time_ms: float) -> None:\n        \"\"\"Record metrics for a single image enrichment.\"\"\"\n        self.images_processed += 1\n        self.total_processing_time_ms += processing_time_ms\n\n        if success:\n            self.enrichments_generated += 1\n        else:\n            self.processing_errors += 1\n\n    def get_summary(self) -> Dict[str, Any]:\n        \"\"\"Get metrics summary.\"\"\"\n        avg_latency = (\n            self.total_processing_time_ms / self.images_processed\n            if self.images_processed > 0 else 0\n        )\n\n        success_rate = (\n            self.enrichments_generated / self.images_processed\n            if self.images_processed > 0 else 0\n        )\n\n        return {\n            \"images_processed\": self.images_processed,\n            \"enrichments_generated\": self.enrichments_generated,\n            \"success_rate\": success_rate,\n            \"average_latency_ms\": avg_latency,\n            \"processing_errors\": self.processing_errors,\n            \"validation_errors\": self.validation_errors,\n        }"
  }
}